{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e6485-2d54-46df-9871-9ea8ae10b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Fix the random seed to facilitate grading\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7d468-d1f8-429b-99d7-d1568ae54527",
   "metadata": {},
   "source": [
    "# HW2.2 - Applying constrained optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa00ec6-4b6f-4b15-9310-6dbaf5cbbc1a",
   "metadata": {},
   "source": [
    "## 2.a Forward Kinematics with IPOPT (26 pts)\n",
    "\n",
    "The problem we study in this homework is the simplified model of our pick-and-place compliant robotics platform that we are using in the practicals of the class.\n",
    "\n",
    "In lectures, we derived a simple model for this system. The optimization problem that we can solve to calculate the forward kinematics calculates, given the lengths $l_1$ and $l_2$, the end-effector position $p$ at equilibrium. We can do this by minimizing the total potential energy. The resulting optimization formulation is:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\min_{\\delta_1,\\delta_2,\\theta_1,\\theta_2,p}\\quad &\n",
    "\\frac{1}{2}k_1 \\delta_1^2 + \\frac{1}{2}k_2 \\delta_2^2 - mg\\,p_y\\\\\n",
    "\\text{s.t.}\\quad \n",
    "& (\\ell_1+\\delta_1)\\cos\\theta_1 = p_x,\\\\\n",
    "& (\\ell_1+\\delta_1)\\sin\\theta_1 = p_y,\\\\\n",
    "& b+(\\ell_2+\\delta_2)\\cos\\theta_2 = p_x,\\\\\n",
    "& (\\ell_2+\\delta_2)\\sin\\theta_2 = p_y,\\\\\n",
    "& \\delta_1\\ge 0,\\ \\delta_2\\ge 0,\\ \\ell_1\\ge 0,\\ \\ell_2\\ge 0,\\\\\n",
    "& 0\\le \\theta_1\\le \\pi,\\ 0\\le \\theta_2\\le \\pi.\n",
    "\\end{aligned}\n",
    "**where:**\n",
    "\n",
    "- $p = (p_x, p_y)$ is the end-effector position, where the x-axis points to the right an the y-axis points downward.  \n",
    "- $\\ell_1, \\ell_2$ are the controllable arm lengths governed by the corresponding motor angles  \n",
    "- $\\delta_1, \\delta_2$ are the spring extensions  \n",
    "- $\\theta_1, \\theta_2$ are the arm orientation angles measured from the horizontal axis, clockwise\n",
    "- $k_1, k_2$ are the spring stiffness coefficients  \n",
    "- $m$ is the end-effector mass and $g$ is the gravitational acceleration  \n",
    "- $b$ is the distance between the two arm bases\n",
    "\n",
    "**2.a.1** Using the autodifferentiation library __casadi__ and the general-purpose solver __IPOPT__, solve this problem numerically. (10 pts)\n",
    "\n",
    ". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import casadi as ca\n",
    "\n",
    "k1 = 100.0\n",
    "k2 = 120.0\n",
    "m  = 5.0\n",
    "grav  = 9.81\n",
    "b = 2.0\n",
    "\n",
    "def solve_forward_kinematics(l, d0=None, t0=None, p0=None, verbose=True):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    - f, the optimal cost\n",
    "    - theta, the vector of two angles at equilibrium\n",
    "    - delta, the vector of two spring extensions at equilibrium\n",
    "    - p, the end-effector position at equilibrium\n",
    "    - lambda, the dual variables of the equality constraints\n",
    "    - mus, the dual variables of the inequality constraints\n",
    "    \"\"\"\n",
    "    ### ============= 2.a.1 Fill in below ==============\n",
    "    opti = ca.Opti()\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Decision variables\n",
    "    delta = opti.variable(2)\n",
    "    theta = opti.variable(2)\n",
    "    p = opti.variable(2)\n",
    "\n",
    "    NotImplementedError\n",
    "\n",
    "    return f, theta, delta, p, lambdas, mus\n",
    "    \n",
    "    ### ===========================\n",
    "\n",
    "f, theta, delta, p, lambdas, mus = solve_forward_kinematics([0.5, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c197fb-c2d1-46f2-90a7-03903cad92be",
   "metadata": {},
   "source": [
    "**2.a.2** Verify that your implementation works using the below plotting function: solve forward kinematics over a selection of lengths and visualize the resulting equilibrium end-effector position $p_x, p_y$. Comment on why you believe this shows that the function works as expected, commenting on the trend and a specific example (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ac87b-c9da-44d1-9ed5-175d8c01c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_setup(p, ax=None, color=\"k\", label=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "    fig.set_size_inches(5, 5)\n",
    "    ax.scatter(0, 0, color=\"k\", s=50, marker=\"o\")\n",
    "    ax.scatter(b, 0, color=\"k\", s=50, marker=\"o\")\n",
    "    ax.scatter(p[0], -p[1], color=\"k\", s=50, marker=\"o\")\n",
    "    ax.plot([0, b], [0, 0], color=\"k\", lw=5)\n",
    "    ax.plot([0, p[0]], [0, -p[1]], color=color, label=label)\n",
    "    ax.plot([b, p[0]], [0, -p[1]], color=color, label=None)\n",
    "    ax.axis(\"equal\")\n",
    "    ax.set_ylim(-1.0, None)\n",
    "    return ax \n",
    "\n",
    "### ============= 2.a.2 Fill in below ==============\n",
    "\n",
    "NotImplementedError\n",
    "\n",
    "### ==========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4b751-b78e-4a08-9cad-a2230a607299",
   "metadata": {},
   "source": [
    "**Answer**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a731a-253e-4ac1-b9ab-a11a57bfe4fb",
   "metadata": {},
   "source": [
    "**2.a.3** Comment on the values of all dual variables:\n",
    "\n",
    "- $\\lambda_1$ to $\\lambda_4$ for the equality constraints\n",
    "- $\\mu_1$ to $\\mu_6$ for the bounds\n",
    "\n",
    "What is the phyiscal meaning of these constraints? (4 pts)\n",
    "\n",
    "Answers:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e34fc57-6b87-4b60-b23e-f0016e69d246",
   "metadata": {},
   "source": [
    "**2.a.4** Investigate the solver output (Set `print_level = 5`) and answer the following questions (8 pts)\n",
    "\n",
    "- How many decision variables, equality constraints, and inequality constraints are present in the problem?\n",
    "- What convergence criteria does IPOPT use, and how many iterations are required for convergence?\n",
    "- How sensitive is the convergence to the choice of initial guesses?\n",
    "- Are all constraints satisfied within the specified tolerance at convergence?\n",
    "\n",
    "**Answer**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be28710-65db-4b46-ab6a-c37da97efeba",
   "metadata": {},
   "source": [
    "## 2.b Forward Kinematics with SQP (20 pts)\n",
    "\n",
    "Now that you have gotten a good feel for this optimization problem and that you have a robust way of solving it, you are in a good position to try your own solvers instead of IPOPT. In class, you have seen a simple algorithm to solve equality-constrained programs: sequential quadratic programming. In what follows, we will ignore the inequality constraints from above. \n",
    "\n",
    "**2.b.1** Explain briefly when we can ignore the inequality constraints, and justify why it makes sense here. How can you check (a posteriori) that it was fine to ignore them? (2 pts)\n",
    "\n",
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e167491-1c26-4ffa-9a51-cdffc17cb73e",
   "metadata": {},
   "source": [
    "**2.b.2** We will use casadi's autodiff framework to find gradients and Hessians. You could find them symbolically as well, but can be error-prone. Since the syntax is a bit confusing at first, we provide a toy example of this framework below. Using this example as guidance, implement the gradient and Hessians of the cost and constraints. Use the following unit test to check that things work: solve the problem for a given $\\ell_1, \\ell_2$ using IPOPT. Check the KKT conditions at the obtained solution using your newly defined function gradient and constraint Jacobian. (4 pts)\n",
    "\n",
    "Note: IPOPT’s equality-constraint multipliers can be positive or negative. The sign depends on how the kinematic constraints are written:\n",
    "For example, the constraint\n",
    "\n",
    "$c3 = b + (l[1] + \\delta[1]) \\cos(\\theta[1]) == p[0]$\n",
    "\n",
    "it can be represented as either\n",
    "\n",
    "$b + (l[1] + \\delta[1]) \\cos(\\theta[1]) - p[0] = 0$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$p[0] - b - (l[1] + \\delta[1]) \\cos(\\theta[1]) = 0.$\n",
    "\n",
    "Both formulations define the same feasible set $g(x) = 0$, or $-g(x) = 0$, but they differ by a sign. As a result, the associated dual variable $\\lambda$ will differ by a sign.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Tutorial for calculating gradient and jacobian from casadi\n",
    "# ----------------------------\n",
    "# Toy example:\n",
    "#   f(x) = x0^2 + sin(x1)\n",
    "#   g(x) = [x0 + x1,\n",
    "#           x0 * x1]\n",
    "# ----------------------------\n",
    "\n",
    "# 1) Build symbolic expressions\n",
    "_x = ca.SX.sym(\"x\", 2)\n",
    "\n",
    "_f = _x[0]**2 + ca.sin(_x[1])\n",
    "_g = ca.vertcat(\n",
    "    _x[0] + _x[1],\n",
    "    _x[0] * _x[1],\n",
    ")\n",
    "_lam = ca.SX.sym(\"lam\", _g.size1())\n",
    "_L = _f + ca.dot(_lam, _g)\n",
    "\n",
    "# 2) Build CasADi Functions (symbolic -> callable)\n",
    "_f_fun    = ca.Function(\"f\",      [_x], [_f])\n",
    "_g_fun    = ca.Function(\"g\",      [_x], [_g])\n",
    "_fgradfun = ca.Function(\"f_grad\", [_x], [ca.gradient(_f, _x)])   # shape (2,1) or (2,)\n",
    "_gjacfun  = ca.Function(\"g_jac\",  [_x], [ca.jacobian(_g, _x)])   # shape (2,2)\n",
    "_L_hess   = ca.Function(\"L_hess\", [_x, _lam], [ca.hessian(_L, _x)[0]]) # shape (2, 2)\n",
    "\n",
    "# 3) Python-callable wrappers (NumPy in/out)\n",
    "def f(x: np.ndarray) -> float:\n",
    "    return float(_f_fun(x))\n",
    "\n",
    "def g(x: np.ndarray) -> np.ndarray:\n",
    "    return np.asarray(_g_fun(x), dtype=float)\n",
    "\n",
    "def f_grad(x: np.ndarray) -> np.ndarray:\n",
    "    return np.asarray(_fgradfun(x), dtype=float)\n",
    "\n",
    "def g_jac(x: np.ndarray) -> np.ndarray:\n",
    "    return np.asarray(_gjacfun(x), dtype=float)\n",
    "\n",
    "def L_hess(x: np.ndarray, lam: np.ndarray) -> np.ndarray:\n",
    "    return np.asarray(_L_hess(x, lam), dtype=float)\n",
    "\n",
    "x0 = np.array([1.0, 0.5])  # fixed test point\n",
    "l0 = np.array([0.5, 0.5])\n",
    "# analytic values\n",
    "print(\"f(x0) =\", f(x0))\n",
    "print(\"g(x0) =\", g(x0))\n",
    "print(\"f_grad(x0) =\", f_grad(x0))\n",
    "print(\"g_jac(x0) =\", g_jac(x0))\n",
    "print(\"L_hess(x0) =\", L_hess(x0, l0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd387610",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0.5, 1.0]\n",
    "l1, l2 = l\n",
    "\n",
    "### ============= 2.b.2 Fill in below ==============\n",
    "\n",
    "\n",
    "\n",
    "_f_fun    = None\n",
    "_g_fun    = None\n",
    "_fgradfun = None\n",
    "_gjacfun  = None\n",
    "_Lhessfun = None\n",
    "\n",
    "### ===========================\n",
    "\n",
    "# ---- Python-callable wrappers\n",
    "def f(x: np.ndarray) -> float:\n",
    "    return float(_f_fun(x))\n",
    "\n",
    "def g(x: np.ndarray) -> np.ndarray:\n",
    "    return np.asarray(_g_fun(x)).flatten()\n",
    "\n",
    "def f_grad(x: np.ndarray) -> np.ndarray:\n",
    "    return np.asarray(_fgradfun(x)).flatten()\n",
    "\n",
    "def g_jac(x: np.ndarray) -> np.ndarray:\n",
    "    return np.asarray(_gjacfun(x))\n",
    "    \n",
    "def L_hess(x: np.ndarray, l: np.ndarray) -> np.ndarray:\n",
    "    return np.asarray(_Lhessfun(x, l), dtype=float)\n",
    "\n",
    "def test_kkt():\n",
    "    f_cost, theta, delta, p, lambdas, mus = solve_forward_kinematics(l, verbose=False)\n",
    "    x0 = np.hstack([theta, delta, p])\n",
    "    # Check the KKT conditions at the obtained solution using your newly defined function gradient and constraint Jacobian.\n",
    "    NotImplementedError\n",
    "    \n",
    "\n",
    "test_kkt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2eb34-7779-4ffc-ae9e-4af270cd163d",
   "metadata": {},
   "source": [
    "**2.b.2** (10 pts) Use a SQP solver to solve this problem. To make your life easier, and for you to practice \"test-driven development\", we have implemented a couple of unit tests for you that should pass for the developed function. \n",
    "\n",
    "These tests are, in order of increasing complexity: \n",
    "- test_cost: ensuring the cost at the minimum is smaller than cost at a random feasible point\n",
    "- test_kkt: checking KKT conditions at the solution.\n",
    "- test_ipopt: comparing solution with IPOPT\n",
    "\n",
    "Using these tests as guidance, fill in sqp_eq_newton until all three tests pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3c628-6f28-4090-a5d2-1a59a340528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cost(fun, **kwargs):\n",
    "    # create a random feasible point\n",
    "    p0 = np.ones(2)\n",
    "    t0 = np.array([np.pi / 4, 3 * np.pi / 4])\n",
    "    d0 = np.array([np.sqrt(2) - l1, np.sqrt(2) - l2])\n",
    "\n",
    "    x0 = np.hstack([t0, d0, p0])\n",
    "    np.testing.assert_almost_equal(g(x0), 0.0)\n",
    "\n",
    "    x_star, lam_star, *_ = fun(x0, **kwargs)\n",
    "    assert f(x_star) <= f(x0)\n",
    "\n",
    "def test_kkt(fun, x0, **kwargs):\n",
    "    x_star, lam_star, *_ = fun(x0, **kwargs)\n",
    "\n",
    "    Lag_x = f_grad(x_star) - g_jac(x_star).T @ (lam_star)\n",
    "    np.testing.assert_almost_equal(g(x_star), 0.0)\n",
    "    np.testing.assert_almost_equal(Lag_x, 0.0)\n",
    "\n",
    "def test_ipopt(fun, x0, **kwargs):\n",
    "    t0 = x0[:2]\n",
    "    d0 = x0[2:4]\n",
    "    p0 = x0[4:]\n",
    "    f_ipopt, t_ipopt, d_ipopt, p_ipopt, lam_ipopt, mus = solve_forward_kinematics(\n",
    "        l, d0=d0, t0=t0, p0=p0, verbose=False\n",
    "    )\n",
    "    x_ipopt = np.hstack([t_ipopt, d_ipopt, p_ipopt])\n",
    "\n",
    "    l0 = np.full(4, 30.0)\n",
    "    x_sqp, lam_sqp, info, *_ = fun(x0, l0=l0, **kwargs)\n",
    "\n",
    "    t_sqp, d_sqp, p_sqp = x_sqp[:2], x_sqp[2:4], x_sqp[4:]\n",
    "    f_sqp = f(x_sqp)\n",
    "\n",
    "    atol = 1e-5\n",
    "    assert abs(f_sqp - f_ipopt) < atol, f\"not equal: {f_sqp:.5e}, {f_ipopt:.5e}\"\n",
    "    np.testing.assert_allclose(t_ipopt, t_sqp, atol=atol)\n",
    "    np.testing.assert_allclose(d_ipopt, d_sqp, atol=atol)\n",
    "    np.testing.assert_allclose(p_ipopt, p_sqp, atol=atol)\n",
    "    np.testing.assert_allclose(lam_ipopt, lam_sqp, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be497508-afb0-46d2-bc1a-bc91f615ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqp_eq_newton(\n",
    "    x0: np.ndarray,\n",
    "    l0: np.ndarray | None = None,\n",
    "    max_iter: int = 50,\n",
    "    tol: float = 1e-9,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    ### ============= 2.b.2 Fill in below ==============\n",
    "    \n",
    "    x = np.asarray(x0, dtype=float).reshape(-1)\n",
    "    m = g(x).shape[0]\n",
    "    lam = l0 if l0 is not None else np.zeros(m)\n",
    "    \n",
    "    n = x.size\n",
    "    res_pri_list = []\n",
    "    res_dual_list = []\n",
    "    x_list = [x.copy()]\n",
    "    success = False\n",
    "\n",
    "    alpha = 1.0\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        NotImplementedError\n",
    "\n",
    "    if verbose: \n",
    "        print(\"x* =\", x)\n",
    "        print(\"lambda* =\", lam)\n",
    "        print(\"g(x*) =\", g(x))\n",
    "    if not success: \n",
    "        print(\"Warning: SQP did not converge!\")\n",
    "    info = {\"iters\": k, \"success\": success}\n",
    "    return x, lam, info, res_pri_list, res_dual_list, x_list\n",
    "    ### ===========================\n",
    "\n",
    "\n",
    "x0 = np.hstack([np.array([0.1, np.pi-0.1]), np.zeros(2), np.zeros(2)])  # good-ish init\n",
    "l0 = np.ones(4)\n",
    "x_sqp, lam_sqp, info, res_pri_list, res_dual_list, x_list = sqp_eq_newton(\n",
    "    x0, l0=l0, verbose=True\n",
    ")\n",
    "print(\"info\", info)\n",
    "print(\"x* =\", x_sqp)\n",
    "print(\"lambda* =\", lam_sqp)\n",
    "print(\"g(x*) =\", g(x_sqp))\n",
    "\n",
    "test_cost(sqp_eq_newton)\n",
    "test_kkt(sqp_eq_newton, x0)\n",
    "test_ipopt(sqp_eq_newton, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5b4da",
   "metadata": {},
   "source": [
    "**2.b.4** Plot convergence and comment on the behavior. You can copy the code from HW2.1, 1.b.2. Compare the performance with IPOPT and comment on the difference and commonalities with IPOPT. (4 pts)\n",
    "\n",
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============= 2.b.4 Fill in below ==============\n",
    "\n",
    "def plot_convergence_rate(res_pri_list, res_dual_list, x_list):    \n",
    "    NotImplementedError\n",
    "    \n",
    "### ===========================\n",
    "\n",
    "plot_convergence_rate(res_pri_list, res_dual_list, x_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f1e0c-c14b-4cdd-a1b7-36d021ed3a2d",
   "metadata": {},
   "source": [
    "## 2.c Forward Kinematics with ALM (17 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6d62c-6307-4599-9dc3-7b7bb8b01e2f",
   "metadata": {},
   "source": [
    "Now, let's see how the convergence changes when we use the Augmented Lagrangian with the method of multipliers instead. \n",
    "\n",
    "Recall that Augmented Lagrangian iterates two steps: \n",
    "- minimize (approximately) the Augmented Lagrangian, keeping current $\\lambda$ fixed\n",
    "- update $\\lambda$ using dual ascent rule.\n",
    "\n",
    "**2.c.1** Create the inner optimization loop which minimizes the Augmented Lagrangian for fixed $\\lambda$. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23fe2b-2876-4b17-99f2-e3354e40beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============= 2.c.1 Fill in below ==============\n",
    "# ---- Build CasADi functions for this problem\n",
    "\n",
    "_Lrho_fun    = None\n",
    "_Lrho_grad_fun = None\n",
    "_Lrho_hess_fun = None\n",
    "\n",
    "### ===========================\n",
    "\n",
    "def Lrho(x, lam, rho) -> np.ndarray:\n",
    "    return np.asarray(_Lrho_fun(x, lam, rho), dtype=float).flatten()[0]\n",
    "\n",
    "def Lrho_grad(x, lam, rho) -> np.ndarray:\n",
    "    return np.asarray(_Lrho_grad_fun(x, lam, rho), dtype=float)\n",
    "    \n",
    "def Lrho_hess(x, lam, rho) -> np.ndarray:\n",
    "    return np.asarray(_Lrho_hess_fun(x, lam, rho), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373b745-2fad-4ce1-bdd9-94e6a639cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============= 2.c.1 Fill in below ==============\n",
    "# ------- Solve inner minimization\n",
    "def solve_inner(x0, lam0, rho, verbose=False, max_inner=200, tol_inner=1e-2):\n",
    "    alpha = 0.1\n",
    "    x = x0\n",
    "    lam = lam0\n",
    "\n",
    "    success = False\n",
    "    \n",
    "    for i in range(max_inner):\n",
    "        NotImplementedError\n",
    "    \n",
    "    info = {\"iters\": i, \"success\": success}\n",
    "    return x, info\n",
    "### ===========================\n",
    "\n",
    "solve_inner(np.zeros(6), np.zeros(4), 0.1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27cfe4-c88e-41e8-a3fe-b8ab3f4ffb1d",
   "metadata": {},
   "source": [
    "**2.c.2** Implement the method of multipliers method below. Verify the correctness of the solution by applying the same unit tests as above. (10 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47ef40-8cbf-4b75-b63f-4732aedd47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alm_solve(\n",
    "    x0,\n",
    "    max_outer=200,\n",
    "    max_inner=200,\n",
    "    tol_outer=1e-7,\n",
    "    tol_inner=1e-7,\n",
    "    rho0=1e-2,\n",
    "    rho_growth=10.0,\n",
    "    verbose=False,\n",
    "    l0 = None\n",
    "):\n",
    "    ### ============= 2.c.2 Fill in below ==============\n",
    "    x = np.asarray(x0, float).reshape(-1)\n",
    "    rho = rho0\n",
    "    gx = np.asarray(g(x), float).reshape(-1)\n",
    "    m = gx.size\n",
    "    lam = l0 if l0 is not None else np.ones(m)\n",
    "\n",
    "    res_pri_list = []\n",
    "    res_dual_list = []\n",
    "    x_list = []\n",
    "    \n",
    "    success = False\n",
    "    alpha = 0.1\n",
    "\n",
    "    for outer in range(max_outer):\n",
    "        NotImplementedError\n",
    "        \n",
    "    ### ===========================\n",
    "        \n",
    "    info = {\"success\": success, \"iters\": outer}\n",
    "    return x, lam, info, res_pri_list, res_dual_list, x_list\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "x0 = np.hstack([np.array([0.1, np.pi-0.1]),np.zeros(2), np.zeros(2)])\n",
    "l0 = np.full(4, 30.0)\n",
    "\n",
    "x_alm, lam_alm, info_alm, res_pri_list, res_dual_list, x_list = alm_solve(\n",
    "    x0,\n",
    "    verbose=True,\n",
    "    l0=l0\n",
    ")\n",
    "print(\"info\", info)\n",
    "print(\"x_alm =\", x_alm.round(4))\n",
    "print(\"lambda_alm =\", lam_alm)\n",
    "print(\"g(x_alm) =\", g(x_alm)) \n",
    "\n",
    "test_cost(alm_solve)\n",
    "test_kkt(alm_solve, x0)\n",
    "test_ipopt(alm_solve, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24c2f6-2419-4442-a187-95d6e59ac736",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_rate(res_pri_list, res_dual_list, x_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c093f0-1c16-45aa-8610-68105cad174c",
   "metadata": {},
   "source": [
    "**2.c.3** To conclude, briefly comment on your experience in writing these solvers. Which solver was easier to implement? Considering their different performance and ease of implementation, comment on settings in which you would prefer one solver over the other. (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1bd464-c0c9-40eb-87a7-65aa4ae6f8aa",
   "metadata": {},
   "source": [
    "# 2.d Packaging of functions (10 pts)\n",
    "\n",
    "**2.d.1** Move the relevant functions to the package you created in the last notebook. Then make sure you create some tests and show their outputs, as in the example below. (5 pts)\n",
    "\n",
    "List of NLP solvers that need to move to this package:\n",
    "- SQP method for NLP with equality constraints\n",
    "- Augmented Lagrangian solver for NLP with equality constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799a6fb-4c76-4c9f-bdab-eeaae50ea77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest myoptim/tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe50ea1-b4ce-4468-a41c-b431ec51f306",
   "metadata": {},
   "source": [
    "**2.d.2** Answer the questions below about the package that you created. Note that there is no right or wrong; these questions serve to make you reflect about what you have implemented. (5 pts)\n",
    "- What tests did you implement? Explain each test with one short sentence.\n",
    "- Are you sure that your code works based on these tests? Reflect on whether all crucial aspects of the code are tested. What could still go wrong? \n",
    "- Is the interface to your code straightforward (i.e., how many lines of code are required to run the solvers? Would it be easy for someone to use it? A good sanity check is if your code is modular so that many functions can be easily tested.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e9e89-80b8-4661-923b-2739daaa8831",
   "metadata": {},
   "source": [
    "## Acknowledgment of Collaboration and/or Tool Use\n",
    "\n",
    "Please choose from below (simply delete the lines that do not apply) and add a few additional notes\n",
    "\n",
    "- “I worked alone on this assignment.”, or\n",
    "- “I worked with ~~~~~~ [person or tool] on this assignment.” and/or\n",
    "- “I received assistance from ~~~~~~ [person or tool] on this assignment.”\n",
    "\n",
    "For the last two cases, specify how the person or tool helped you and explain why this amplified your learning process:\n",
    "\n",
    "_add answer here_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
